{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee559b76",
      "metadata": {
        "id": "ee559b76"
      },
      "source": [
        "## Imports and setups"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cd548a",
      "metadata": {
        "id": "06cd548a"
      },
      "source": [
        "Substitute variables with appropriate file paths/selections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629c64d7",
      "metadata": {
        "id": "629c64d7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/Users/isaacdaviet/Desktop/thesis/python_versions')\n",
        "# replace with directory containing the .py calculation files below\n",
        "import clustering_functions as clustering\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d230be1e",
      "metadata": {
        "id": "d230be1e"
      },
      "outputs": [],
      "source": [
        "project_name = 'Mason'\n",
        "# Name of project for file saving and graph title purposes\n",
        "\n",
        "selected_pca_plotly_folder = r'/Users/isaacdaviet/Desktop/results/PCA_analysis/PCAs_of_interest/final_pcas_of_interest'\n",
        "# folder containing .csv files of umap reductions from previous step (umap_final_plot_generation.ipynb)\n",
        "\n",
        "selected_graphs_csv = r'/Users/isaacdaviet/Desktop/graphs/clustering/mason_umap_clustering_analysis_binders.csv'\n",
        "# csv file containing ranges to test/plot. column format: [distance metric, start neighbors, end neighbors, neighbors step, start dist, end dist, dist step]. INCLUDE THESE EXACT COLUMN NAMES"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8021eb8",
      "metadata": {
        "id": "d8021eb8"
      },
      "source": [
        "## Generate list of PC combos from folder containing final plotly graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7af758",
      "metadata": {
        "id": "3a7af758"
      },
      "outputs": [],
      "source": [
        "labeled_seq_csv_file = r'/Users/isaacdaviet/Desktop/mason_igfold_models/mason_sequences_label.csv'\n",
        "# csv file containing sequences in column 1 and their status as binder (1)/non all (0) in the second column\n",
        "\n",
        "selected_pca_plotly_folder = r'/Users/isaacdaviet/Desktop/results/PCA_analysis/PCAs_of_interest/final_pcas_of_interest'\n",
        "\n",
        "pca_df = r'/Users/isaacdaviet/Desktop/results/PCA_analysis/mason-PCAdf95.csv'\n",
        "\n",
        "pca_df_iseq = clustering.add_seqs_umap_df(pca_df, labeled_seq_csv_file)\n",
        "\n",
        "pca_df_iseq.to_csv(pca_df, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2803d679",
      "metadata": {
        "id": "2803d679",
        "outputId": "8dfd36bf-bac5-48e2-d030-7f232eb6a9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       PCA3_ExpVar:4.20%  PCA7_ExpVar:2.96%      Labels   Sequences   iseq\n",
            "0               0.001049           0.014570  Non Binder  WPTNAMFMHS  12740\n",
            "1               0.004517           0.040964  Non Binder  WSMSAFFMYM  21527\n",
            "2              -0.029688          -0.035011  Non Binder  FFDTSSFAFA  21135\n",
            "3               0.000650           0.044158  Non Binder  YADYGLFHIH   9127\n",
            "4              -0.060888          -0.091178  Non Binder  FPMHRHYVIK  23527\n",
            "...                  ...                ...         ...         ...    ...\n",
            "34141          -0.045774           0.079494  Non Binder  YEAASLYAND   9973\n",
            "34142          -0.025123           0.013244  Non Binder  WLIPGFFVYM  23700\n",
            "34143           0.038876          -0.029588  Non Binder  WDLVRHFENP  24367\n",
            "34144          -0.010265          -0.014975  Non Binder  WMESAMYPHI  10973\n",
            "34145          -0.035811          -0.085658  Non Binder  FRQVDFYIHP  14581\n",
            "\n",
            "[34146 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "html_files = [file for file in os.listdir(selected_pca_plotly_folder) if file.endswith('.html')]\n",
        "\n",
        "# extract pc combos from names of plotly html file names in folder\n",
        "pc_combos = []\n",
        "for entry in html_files:\n",
        "    combo = entry.split('_')[-1]\n",
        "    combo = combo.replace('.html', '')\n",
        "    combo = combo.replace('PCA', '')\n",
        "    combo = combo.split('-')\n",
        "\n",
        "    pc_combos.append(combo)\n",
        "\n",
        "column_names = ['pc1', 'pc2', 'eps', 'min_samples', 'generate']\n",
        "optimization_csv_df = pd.DataFrame(columns = column_names)\n",
        "\n",
        "# generate unique dfs for each combo\n",
        "all_dfs = []\n",
        "for combo in pc_combos:\n",
        "\n",
        "    x_column = pca_df_iseq.filter(like=f'PCA{pc1}_', axis=1)\n",
        "    x_axes = x_column.columns.tolist()[0]\n",
        "    y_column = pca_df_iseq.filter(like=f'PCA{pc2}_', axis=1)\n",
        "    y_axes = y_column.columns.tolist()[0]\n",
        "\n",
        "    X = pd.DataFrame(pca_df_iseq, columns=[x_axes, y_axes])\n",
        "    X['Labels'] = pd.DataFrame(pca_df_iseq, columns=['label'])\n",
        "    X['Sequences'] = pd.DataFrame(pca_df_iseq, columns=['Sequences'])\n",
        "    X['iseq'] = pd.DataFrame(pca_df_iseq, columns=['iseq'])\n",
        "    all_dfs.append(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0deae6",
      "metadata": {
        "id": "4a0deae6"
      },
      "outputs": [],
      "source": [
        "test_df = all_dfs[0]\n",
        "\n",
        "clustered_df = clustering.agglomerative_clustering(test_df, n_clusters, linkage, affinity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60c1896",
      "metadata": {
        "id": "f60c1896",
        "outputId": "49e2874b-0ac9-47a9-fd2b-61221d5fec59"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m unique_positive_fv \u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/isaacdaviet/Desktop/mason_igfold_models/mason_igfold_models/outfile/mHER_H3_AgPos_unique_fv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m unique_negative_fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/isaacdaviet/Desktop/mason_igfold_models/mason_igfold_models/outfile/mHER_H3_AgNeg_unique_fv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m clustering\u001b[38;5;241m.\u001b[39madd_iseq_to_labels_file(labeled_seq_csv_file, unique_positive_fv, unique_negative_fv)\n",
            "File \u001b[0;32m~/Desktop/thesis/python_versions/clustering_functions.py:55\u001b[0m, in \u001b[0;36madd_iseq_to_labels_file\u001b[0;34m(labeled_seq_csv_file, unique_positive_fv, unique_negative_fv)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon Binder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     53\u001b[0m     fv_df \u001b[38;5;241m=\u001b[39m neg_fv_df\n\u001b[0;32m---> 55\u001b[0m match_row \u001b[38;5;241m=\u001b[39m fv_df[fv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhseq\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(sequence)]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match_row\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     57\u001b[0m     iseq \u001b[38;5;241m=\u001b[39m match_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miseq\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/accessor.py:1289\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regex \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mcompile(pat)\u001b[38;5;241m.\u001b[39mgroups:\n\u001b[1;32m   1282\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1287\u001b[0m     )\n\u001b[0;32m-> 1289\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result, fill_value\u001b[38;5;241m=\u001b[39mna, returns_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/object_array.py:143\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    141\u001b[0m         upper_pat \u001b[38;5;241m=\u001b[39m pat\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m    142\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: upper_pat \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_str_map(f, na, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/object_array.py:76\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[0;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[1;32m     74\u001b[0m map_convert \u001b[38;5;241m=\u001b[39m convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(mask)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     result \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(arr, f, mask\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), map_convert)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     p_err \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m((takes)|(missing)) (?(2)from \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ to )?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?(3)required )positional arguments?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2786\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/object_array.py:136\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mIGNORECASE\n\u001b[1;32m    134\u001b[0m     pat \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pat, flags\u001b[38;5;241m=\u001b[39mflags)\n\u001b[0;32m--> 136\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: pat\u001b[38;5;241m.\u001b[39msearch(x) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m case:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "unique_positive_fv =r'/Users/isaacdaviet/Desktop/mason_igfold_models/mason_igfold_models/outfile/mHER_H3_AgPos_unique_fv.csv'\n",
        "\n",
        "unique_negative_fv = r'/Users/isaacdaviet/Desktop/mason_igfold_models/mason_igfold_models/outfile/mHER_H3_AgNeg_unique_fv.csv'\n",
        "\n",
        "clustering.add_iseq_to_labels_file(labeled_seq_csv_file, unique_positive_fv, unique_negative_fv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606a7059",
      "metadata": {
        "id": "606a7059"
      },
      "source": [
        "# Optimize clustering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2231b5",
      "metadata": {
        "id": "3b2231b5"
      },
      "source": [
        "Run each umap selection individually until desired clusters are acheived. When satified, switch 'generate' column to done.\n",
        "\n",
        "Steps:\n",
        "- select which clustering algorithm to use and which point type (binders/non binders) to use\n",
        "- In the 'selected_graphs_csv' file, fill the generate column with 'y' for the graphs you would like to optimize\n",
        "- Fill in the variables in the csv file for the appropriate algorithm (dbscan_eps + dbscan_min_samples for dbscan and agg_n_clusters and agg_linkage for agglomerative)\n",
        "- Save changes to csv file and run cell below\n",
        "- Analyze resulting plotly and adjust parameters until satisified with the clustering\n",
        "- Use the 'combine_clusters' column to specify which clusters, if any, should be merged. Note: specifically designed for   clusters that are difficult to cluster as a single group and that would be classified as 'low priority' in the QC steps\n",
        "- When satisfied, switch 'generate' to 'done' and proceed to next graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33482c20",
      "metadata": {
        "id": "33482c20"
      },
      "outputs": [],
      "source": [
        "save_folder = r'/Users/isaacdaviet/Desktop/results/clustering/PCA_dbscan_clusters'\n",
        "#save folder for graphs and cvs files.\n",
        "\n",
        "algorithm = 'dbscan'\n",
        "# Which clustering algorithm to use. As it stands now, dbscan and agglomerative are the only options available.\n",
        "\n",
        "points_to_optimize = 'binders'\n",
        "# what points to show on graphs. 'all' shows binders and non binders in same graph, 'binders' show only binders, 'non binders' shows only non binders\n",
        "\n",
        "\n",
        "clustering.cluster_extract_and_plot(selected_graphs_csv, labeled_seq_csv_file, umap_reductions_folder, clusters = points_to_optimize, algorithm = algorithm, generate_indicator = 'y', plt_size = [60, 20], pt_size = 30, fontsize=64, show_unclustered_pts='n' ,save_graph = 'n', save_folder = save_folder, project_name=project_name, save_clusters_csv = 'n', save_plotly = 'y')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25344856",
      "metadata": {
        "id": "25344856"
      },
      "source": [
        "# Full Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97597d46",
      "metadata": {
        "id": "97597d46"
      },
      "source": [
        "Produces csv, plotly and png graphs of all clusters indicated by 'done' in the generate column. Png images contain original binder/non binder + binder clusters + non binder clusters graphs as a single image.\n",
        "\n",
        "NOTE: cluster graphs in png images DO NOT display any unclustered points, but the plotly graphs do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5eec7c0",
      "metadata": {
        "id": "e5eec7c0"
      },
      "outputs": [],
      "source": [
        "save_folder = r'/Users/isaacdaviet/Desktop/graphs/clustering/dbscan_clusters'\n",
        "#save folder for graphs and cvs files.\n",
        "\n",
        "algorithm = 'dbscan'\n",
        "\n",
        "### Final save (csv, html plotly and subplots)\n",
        "clustering.cluster_extract_and_plot(selected_graphs_csv,\n",
        "                                     labeled_seq_csv_file, umap_reductions_folder,\n",
        "                                     clusters = 'both',\n",
        "                                     algorithm = algorithm,\n",
        "                                     generate_indicator = 'done',\n",
        "                                     plt_size = [60, 20],\n",
        "                                     pt_size = 20,\n",
        "                                     fontsize=64,\n",
        "                                     show_unclustered_pts='n',\n",
        "                                     save_graph = 'n',\n",
        "                                     save_folder = save_folder, project_name=project_name, save_clusters_csv = 'y',\n",
        "                                     save_plotly = 'n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba9b52f8",
      "metadata": {
        "id": "ba9b52f8"
      },
      "source": [
        "# Cluster QC"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566d453a",
      "metadata": {
        "id": "566d453a"
      },
      "source": [
        "Modifies cluster dataframes to create add 'adjusted_clusters', which updates the clusters to reflect the manual cluster combination specified in the combine_clusters column of the cluster_analysis csv file, and a 'priority' column that classifies each point in a cluster as high/med/low/out_of_bounds priority based on percentages used as input parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7c1731",
      "metadata": {
        "id": "8c7c1731"
      },
      "outputs": [],
      "source": [
        "### Manual inspection of a specific data frame's clusters as a percentage of the total number of points for a specific LABEL (ie: (# binders in cluster / total # of binders) * 100)\n",
        "\n",
        "clusters_df = r'/Users/isaacdaviet/Desktop/graphs/clustering/correlation_clusters/csv_files/UMAP_Mason-correlation-3-25-0.0-1-2_dbscanClusters-0.15-20.csv'\n",
        "\n",
        "points = 'non binders'\n",
        "\n",
        "clusters_df = pd.read_csv(clusters_df)\n",
        "\n",
        "priorities = clustering.cluster_priority(clusters_df, high_threshold = 10, low_threshold = 1, upper_limit = None, print_percentages = points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c57a6d3",
      "metadata": {
        "id": "6c57a6d3",
        "outputId": "3f42c785-2c1b-422d-f749-da90428338de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting UMAP_Mason-euclidean-3-140-0.0-2-3_dbscanClusters-0.1-30.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-25-0.0-3-5_dbscanClusters-0.07-20.csv\n",
            "Adjusting UMAP_Mason-cosine-5-35-0.25-4-5_dbscanClusters-0.12-60.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.2-2-5_dbscanClusters-0.08-30.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-185-0.0-2-5_dbscanClusters-0.07-25.csv\n",
            "Adjusting UMAP_Mason-cosine-3-95-0.1-1-3_dbscanClusters-0.1-30.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-140-0.0-4-5_dbscanClusters-0.05-30.csv\n",
            "Adjusting UMAP_Mason-correlation-5-25-0.0-3-5_dbscanClusters-0.12-45.csv\n",
            "Adjusting UMAP_Mason-correlation-3-25-0.0-1-3_dbscanClusters-0.15-30.csv\n",
            "Adjusting UMAP_Mason-cosine-3-95-0.0-2-3_dbscanClusters-0.12-35.csv\n",
            "Adjusting UMAP_Mason-cosine-5-95-0.0-3-4_dbscanClusters-0.09-35.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-45-0.0-3-4_dbscanClusters-0.09-45.csv\n",
            "Adjusting UMAP_Mason-hamming-3-15-0.0-2-3_dbscanClusters-0.1-35.csv\n",
            "Adjusting UMAP_Mason-correlation-3-25-0.0-2-3_dbscanClusters-0.15-30.csv\n",
            "Adjusting UMAP_Mason-correlation-3-95-0.0-1-3_dbscanClusters-0.12-30.csv\n",
            "Adjusting UMAP_Mason-cosine-5-35-0.0-3-5_dbscanClusters-0.09-35.csv\n",
            "Adjusting UMAP_Mason-manhattan-3-65-0.0-1-2_dbscanClusters-0.1-20.csv\n",
            "Adjusting UMAP_Mason-cosine-5-65-0.0-3-4_dbscanClusters-0.09-35.csv\n",
            "Adjusting UMAP_Mason-cosine-5-95-0.0-3-5_dbscanClusters-0.09-35.csv\n",
            "Adjusting UMAP_Mason-cosine-3-35-0.0-1-3_dbscanClusters-0.125-30.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-25-0.15-1-2_dbscanClusters-0.06-15.csv\n",
            "Adjusting UMAP_Mason-correlation-5-95-0.0-2-3_dbscanClusters-0.12-45.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-140-0.0-3-4_dbscanClusters-0.06-25.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.1-1-5_dbscanClusters-0.09-20.csv\n",
            "Adjusting UMAP_Mason-manhattan-3-25-0.0-1-3_dbscanClusters-0.1-25.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.0-1-3_dbscanClusters-0.07-30.csv\n",
            "Adjusting UMAP_Mason-correlation-3-25-0.0-1-2_dbscanClusters-0.15-20.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-45-0.0-4-5_dbscanClusters-0.08-45.csv\n",
            "Adjusting UMAP_Mason-hamming-3-25-0.0-1-3_dbscanClusters-0.1-40.csv\n",
            "Adjusting UMAP_Mason-cosine-5-35-0.0-3-4_dbscanClusters-0.11-40.csv\n",
            "Adjusting UMAP_Mason-hamming-3-15-0.05-1-3_dbscanClusters-0.09-25.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-120-0.0-3-4_dbscanClusters-0.08-45.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-185-0.0-2-4_dbscanClusters-0.07-25.csv\n",
            "Adjusting UMAP_Mason-cosine-5-95-0.1-3-4_dbscanClusters-0.09-35.csv\n",
            "Adjusting UMAP_Mason-manhattan-3-65-0.0-2-3_dbscanClusters-0.09-20.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.1-1-2_dbscanClusters-0.09-20.csv\n",
            "Adjusting UMAP_Mason-correlation-5-95-0.0-2-4_dbscanClusters-0.12-45.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-120-0.1-3-4_dbscanClusters-0.06-20.csv\n",
            "Adjusting UMAP_Mason-correlation-5-25-0.0-1-3_dbscanClusters-0.1-27.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.1-2-5_dbscanClusters-0.09-20.csv\n",
            "Adjusting UMAP_Mason-hamming-5-25-0.1-1-3_dbscanClusters-0.08-30.csv\n",
            "Adjusting UMAP_Mason-correlation-3-25-0.15-1-3_dbscanClusters-0.12-25.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-25-0.15-1-5_dbscanClusters-0.06-25.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-35-0.0-4-5_dbscanClusters-0.1-50.csv\n",
            "Adjusting UMAP_Mason-correlation-5-25-0.0-1-5_dbscanClusters-0.12-30.csv\n",
            "Adjusting UMAP_Mason-cosine-5-35-0.0-4-5_dbscanClusters-0.09-30.csv\n",
            "Adjusting UMAP_Mason-correlation-5-95-0.0-3-4_dbscanClusters-0.12-45.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.0-1-5_dbscanClusters-0.08-20.csv\n",
            "Adjusting UMAP_Mason-manhattan-3-65-0.1-1-3_dbscanClusters-0.1-20.csv\n",
            "Adjusting UMAP_Mason-euclidean-3-120-0.1-2-3_dbscanClusters-0.08-20.csv\n",
            "Adjusting UMAP_Mason-cosine-3-65-0.0-1-3_dbscanClusters-0.125-30.csv\n",
            "Adjusting UMAP_Mason-cosine-3-35-0.25-1-3_dbscanClusters-0.1-20.csv\n",
            "Adjusting UMAP_Mason-hamming-3-25-0.1-2-3_dbscanClusters-0.1-35.csv\n",
            "Adjusting UMAP_Mason-correlation-3-25-0.15-2-3_dbscanClusters-0.12-25.csv\n",
            "Adjusting UMAP_Mason-manhattan-3-25-0.15-1-3_dbscanClusters-0.1-15.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-25-0.15-2-5_dbscanClusters-0.08-20.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-140-0.0-3-5_dbscanClusters-0.05-35.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-120-0.0-3-5_dbscanClusters-0.05-30.csv\n",
            "Adjusting UMAP_Mason-correlation-5-95-0.3-3-4_dbscanClusters-0.075-25.csv\n",
            "Adjusting UMAP_Mason-hamming-5-45-0.0-3-5_dbscanClusters-0.07-40.csv\n",
            "Adjusting UMAP_Mason-correlation-3-95-0.3-2-3_dbscanClusters-0.12-30.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-120-0.0-4-5_dbscanClusters-0.06-35.csv\n",
            "Adjusting UMAP_Mason-euclidean-5-45-0.0-3-5_dbscanClusters-0.08-50.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-65-0.0-3-5_dbscanClusters-0.07-25.csv\n",
            "Adjusting UMAP_Mason-correlation-3-25-0.15-1-2_dbscanClusters-0.12-25.csv\n",
            "Adjusting UMAP_Mason-hamming-5-25-0.0-3-4_dbscanClusters-0.07-40.csv\n",
            "Adjusting UMAP_Mason-manhattan-3-65-0.0-1-3_dbscanClusters-0.08-25.csv\n",
            "Adjusting UMAP_Mason-cosine-5-95-0.0-4-5_dbscanClusters-0.07-35.csv\n",
            "Adjusting UMAP_Mason-manhattan-5-185-0.0-4-5_dbscanClusters-0.06-30.csv\n"
          ]
        }
      ],
      "source": [
        "### Automatically applies cluster adjustment and prioritization to all csv_files in a folder. Thresholds/upper limit are set as percentages\n",
        "\n",
        "high_threshold = 10\n",
        "low_threshold = 1\n",
        "upper_limit = 40\n",
        "\n",
        "\n",
        "clusters_csv_folder = r'/Users/isaacdaviet/Desktop/graphs/clustering/dbscan_clusters'\n",
        "\n",
        "clustering.adjust_clusters_folder(clusters_csv_folder, selected_graphs_csv, point_type = 'Binder', high_threshold = high_threshold, low_threshold = low_threshold, upper_limit = upper_limit)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}